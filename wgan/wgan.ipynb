{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class WGAN():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        # Following parameter and optimizer set as recommended in paper\n",
    "        self.n_critic = 5\n",
    "        self.clip_value = 0.01\n",
    "        optimizer = RMSprop(lr=0.00005)\n",
    "\n",
    "        # Build and compile the critic\n",
    "        self.critic = self.build_critic()\n",
    "        self.critic.compile(loss=self.wasserstein_loss,\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generated imgs\n",
    "        z = Input(shape=(100,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.critic.trainable = False\n",
    "\n",
    "        # The critic takes generated images as input and determines validity\n",
    "        valid = self.critic(img)\n",
    "\n",
    "        # The combined model  (stacked generator and critic)\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss=self.wasserstein_loss,\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "    def wasserstein_loss(self, y_true, y_pred):\n",
    "        return K.mean(y_true * y_pred)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((7, 7, 128)))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=4, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=4, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(self.channels, kernel_size=4, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_critic(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(16, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = -np.ones((batch_size, 1))\n",
    "        fake = np.ones((batch_size, 1))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            for _ in range(self.n_critic):\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Discriminator\n",
    "                # ---------------------\n",
    "\n",
    "                # Select a random batch of images\n",
    "                idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "                imgs = X_train[idx]\n",
    "                \n",
    "                # Sample noise as generator input\n",
    "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "                # Generate a batch of new images\n",
    "                gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "                # Train the critic\n",
    "                d_loss_real = self.critic.train_on_batch(imgs, valid)\n",
    "                d_loss_fake = self.critic.train_on_batch(gen_imgs, fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n",
    "\n",
    "                # Clip critic weights\n",
    "                for l in self.critic.layers:\n",
    "                    weights = l.get_weights()\n",
    "                    weights = [np.clip(w, -self.clip_value, self.clip_value) for w in weights]\n",
    "                    l.set_weights(weights)\n",
    "\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f] [G loss: %f]\" % (epoch, 1 - d_loss[0], 1 - g_loss[0]))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % sample_interval == 0:\n",
    "                self.sample_images(epoch)\n",
    "\n",
    "    def sample_images(self, epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 1\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"images/mnist_%d.png\" % epoch)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 16)        160       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 32)          4640      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 100,097\n",
      "Trainable params: 99,649\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 128)       262272    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 64)        131136    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 1)         1025      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 1,028,673\n",
      "Trainable params: 1,028,289\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidfoster/.virtualenvs/gdl/lib/python3.6/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.999925] [G loss: 1.000124]\n",
      "1 [D loss: 0.999929] [G loss: 1.000131]\n",
      "2 [D loss: 0.999927] [G loss: 1.000115]\n",
      "3 [D loss: 0.999932] [G loss: 1.000123]\n",
      "4 [D loss: 0.999939] [G loss: 1.000117]\n",
      "5 [D loss: 0.999933] [G loss: 1.000125]\n",
      "6 [D loss: 0.999932] [G loss: 1.000123]\n",
      "7 [D loss: 0.999938] [G loss: 1.000128]\n",
      "8 [D loss: 0.999940] [G loss: 1.000117]\n",
      "9 [D loss: 0.999939] [G loss: 1.000118]\n",
      "10 [D loss: 0.999944] [G loss: 1.000127]\n",
      "11 [D loss: 0.999937] [G loss: 1.000114]\n",
      "12 [D loss: 0.999938] [G loss: 1.000124]\n",
      "13 [D loss: 0.999939] [G loss: 1.000119]\n",
      "14 [D loss: 0.999936] [G loss: 1.000119]\n",
      "15 [D loss: 0.999929] [G loss: 1.000119]\n",
      "16 [D loss: 0.999943] [G loss: 1.000116]\n",
      "17 [D loss: 0.999943] [G loss: 1.000113]\n",
      "18 [D loss: 0.999943] [G loss: 1.000119]\n",
      "19 [D loss: 0.999949] [G loss: 1.000112]\n",
      "20 [D loss: 0.999946] [G loss: 1.000095]\n",
      "21 [D loss: 0.999951] [G loss: 1.000094]\n",
      "22 [D loss: 0.999951] [G loss: 1.000084]\n",
      "23 [D loss: 0.999952] [G loss: 1.000082]\n",
      "24 [D loss: 0.999951] [G loss: 1.000082]\n",
      "25 [D loss: 0.999952] [G loss: 1.000082]\n",
      "26 [D loss: 0.999950] [G loss: 1.000079]\n",
      "27 [D loss: 0.999956] [G loss: 1.000074]\n",
      "28 [D loss: 0.999952] [G loss: 1.000072]\n",
      "29 [D loss: 0.999956] [G loss: 1.000076]\n",
      "30 [D loss: 0.999956] [G loss: 1.000068]\n",
      "31 [D loss: 0.999955] [G loss: 1.000070]\n",
      "32 [D loss: 0.999960] [G loss: 1.000070]\n",
      "33 [D loss: 0.999969] [G loss: 1.000080]\n",
      "34 [D loss: 0.999964] [G loss: 1.000070]\n",
      "35 [D loss: 0.999969] [G loss: 1.000067]\n",
      "36 [D loss: 0.999967] [G loss: 1.000065]\n",
      "37 [D loss: 0.999963] [G loss: 1.000074]\n",
      "38 [D loss: 0.999965] [G loss: 1.000078]\n",
      "39 [D loss: 0.999963] [G loss: 1.000074]\n",
      "40 [D loss: 0.999972] [G loss: 1.000062]\n",
      "41 [D loss: 0.999972] [G loss: 1.000067]\n",
      "42 [D loss: 0.999968] [G loss: 1.000076]\n",
      "43 [D loss: 0.999968] [G loss: 1.000069]\n",
      "44 [D loss: 0.999971] [G loss: 1.000083]\n",
      "45 [D loss: 0.999974] [G loss: 1.000083]\n",
      "46 [D loss: 0.999979] [G loss: 1.000065]\n",
      "47 [D loss: 0.999977] [G loss: 1.000068]\n",
      "48 [D loss: 0.999973] [G loss: 1.000074]\n",
      "49 [D loss: 0.999981] [G loss: 1.000074]\n",
      "50 [D loss: 0.999976] [G loss: 1.000076]\n",
      "51 [D loss: 0.999977] [G loss: 1.000085]\n",
      "52 [D loss: 0.999973] [G loss: 1.000072]\n",
      "53 [D loss: 0.999975] [G loss: 1.000073]\n",
      "54 [D loss: 0.999985] [G loss: 1.000077]\n",
      "55 [D loss: 0.999984] [G loss: 1.000082]\n",
      "56 [D loss: 0.999992] [G loss: 1.000081]\n",
      "57 [D loss: 0.999988] [G loss: 1.000073]\n",
      "58 [D loss: 0.999982] [G loss: 1.000083]\n",
      "59 [D loss: 0.999988] [G loss: 1.000077]\n",
      "60 [D loss: 0.999986] [G loss: 1.000076]\n",
      "61 [D loss: 0.999988] [G loss: 1.000092]\n",
      "62 [D loss: 0.999998] [G loss: 1.000099]\n",
      "63 [D loss: 0.999989] [G loss: 1.000094]\n",
      "64 [D loss: 0.999995] [G loss: 1.000097]\n",
      "65 [D loss: 0.999981] [G loss: 1.000113]\n",
      "66 [D loss: 1.000002] [G loss: 1.000117]\n",
      "67 [D loss: 0.999990] [G loss: 1.000107]\n",
      "68 [D loss: 0.999994] [G loss: 1.000110]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3131efb96d20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mwgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-b7d34163a4ee>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, batch_size, sample_interval)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;31m# ---------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;31m# Plot the progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gdl/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gdl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gdl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gdl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wgan = WGAN()\n",
    "wgan.train(epochs=4000, batch_size=32, sample_interval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4.307384e-05], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "# Rescale -1 to 1\n",
    "X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "noise = np.random.normal(0, 1, 100)\n",
    "img = wgan.generator.predict(np.array([noise]))[0]\n",
    "\n",
    "print(img.shape)\n",
    "plt.imshow(img[:,:,0])\n",
    "\n",
    "wgan.critic.predict(np.array([img]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.5986882e-05]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wgan.critic.predict(np.array([X_train[85]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12a4c7588>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[85,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gdl",
   "language": "python",
   "name": "gdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
